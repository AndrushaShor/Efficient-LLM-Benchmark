{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import logging \n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "from datasets import Dataset\n",
    "import accelerate\n",
    "import bitsandbytes\n",
    "\n",
    "from peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training, AdaLoraModel, AdaLoraConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, HfArgumentParser, TrainingArguments, pipeline\n",
    "from trl import SFTTrainer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenized_dataset(self, name:str, file_path:str):\n",
    "    data_dict = {}\n",
    "    with open(file_path, 'r') as fp:\n",
    "        id, questions, answers, text, input_id = json.load(fp)\n",
    "        \n",
    "        data_dict['id'] = id\n",
    "        data_dict['questions'] = questions\n",
    "        data_dict['answers'] = answers\n",
    "        data_dict['text'] = text\n",
    "        data_dict['input_ids'] = input_id\n",
    "        \n",
    "        self.dataset[name] = Dataset.from_dict(data_dict)\n",
    "    \n",
    "    return Dataset.from_dict(data_dict)\n",
    "\n",
    "def load_model(base_model):\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(base_model)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "\n",
    "    return base_model, tokenizer\n",
    "\n",
    "def prepare_lora_model(base_model, lora_config):\n",
    "    peft_model = prepare_model_for_kbit_training(base_model)\n",
    "    lora_model = get_peft_model(peft_model, lora_config)\n",
    "    \n",
    "    return peft_model, lora_model\n",
    "\n",
    "def prepare_adalora_model(base_model, adalora_config, name):\n",
    "    return AdaLoraModel(base_model, adalora_config, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_model, gemma_tokenizer = load_model(\"google/gemma-7b\")\n",
    "llama2, llama2_tokenizer = load_model(\"meta-llama/Llama-2-7b-hf\")\n",
    "mistral_model, mistral_tokenizer = load_model(\"mistralai/Mistral-7B-v0.1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EfficientLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
